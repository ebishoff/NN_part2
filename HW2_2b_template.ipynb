{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebish\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "import load_cifar_template1\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Hyper-perparmeter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.0001\n",
    "#number of traning steps\n",
    "num_steps =15\n",
    "#number of batch_size\n",
    "batch_size = 256\n",
    "\n",
    "#network parameters\n",
    "hidden_layers=2\n",
    "nh1 = 512\n",
    "nh2 = 512\n",
    "#n_hidden_3=512\n",
    "num_input = 3072\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,num_input],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #old way to do things\n",
    "# X = tf.placeholder(tf.float32,[None,num_input],name='X')\n",
    "# Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n",
    "\n",
    "# #Layers weight & bias\n",
    "# weights = {\n",
    "#     'W1': tf.Variable(tf.random_normal([num_input, n_hidden_1]),name='W1'),\n",
    "#     'W2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='W2'),\n",
    "#    # 'W3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]),name='W3'),\n",
    "#     #'W4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4]),name='W4'),\n",
    "\n",
    "#     'Wout': tf.Variable(tf.random_normal([n_hidden_2, num_classes]),name='Wout')\n",
    "# }\n",
    "\n",
    "# biases = {\n",
    "#     'b1': tf.Variable(tf.zeros(shape=[n_hidden_1]),name='b1'),\n",
    "#     'b2': tf.Variable(tf.zeros(shape=[n_hidden_2]),name='b2'),\n",
    "#     #'b3': tf.Variable(tf.zeros(shape=[n_hidden_3]),name='b3'),\n",
    "# #'b4': tf.Variable(tf.zeros(shape=[n_hidden_4]),name='b4'),\n",
    "\n",
    "#     'bout': tf.Variable(tf.zeros(shape=[num_classes]),name='bout')\n",
    "# }\n",
    "\n",
    "# #define a neural net model\n",
    "# def neural_net(x):\n",
    "#     layer_1_out = tf.nn.relu(tf.add(tf.matmul(x,weights['W1']),biases['b1']))\n",
    "#     layer_2_out = tf.nn.relu(tf.add(tf.matmul(layer_1_out,weights['W2']),biases['b2']))\n",
    "\n",
    "\n",
    "#     out = tf.add(tf.matmul(layer_2_out,weights['Wout']),biases['bout'])\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a neural net model\n",
    "def neural_net(x):\n",
    "    layer_1_out = tf.layers.dense(x,units=nh1,activation='relu')\n",
    "    layer_2_out = tf.layers.dense(layer_1_out,units=nh2,activation='relu')\n",
    "\n",
    "    out = tf.layers.dense(layer_2_out,units=num_classes)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define cost andoptimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted labels\n",
    "logits = neural_net(X)\n",
    "\n",
    "#define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y),name='loss')\n",
    "#define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "#compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "\n",
    "#compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n",
    "\n",
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "loss_summary=tf.summary.scalar('loss',loss)\n",
    "accuracy_summary=tf.summary.scalar('accuracy',accuracy)\n",
    "#file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and testing</h1>\n",
    "<h2>1.Print out validation accuracy after each training poch</h2>\n",
    "<h2>2.Print out training time you spend on each epoch</h2>\n",
    "<h2>3.Print out testing accuracy in the end</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Time:24.308100700378418 , Training Accuracy= 0.296\n",
      "Validation Accuracy: 0.3446\n",
      "Epoch 1, Time:25.596235275268555 , Training Accuracy= 0.371\n",
      "Validation Accuracy: 0.3696\n",
      "Epoch 2, Time:23.390486240386963 , Training Accuracy= 0.397\n",
      "Validation Accuracy: 0.4038\n",
      "Epoch 3, Time:23.26980996131897 , Training Accuracy= 0.416\n",
      "Validation Accuracy: 0.4158\n",
      "Epoch 4, Time:23.795584440231323 , Training Accuracy= 0.436\n",
      "Validation Accuracy: 0.42\n",
      "Epoch 5, Time:22.16875195503235 , Training Accuracy= 0.444\n",
      "Validation Accuracy: 0.4322\n",
      "Epoch 6, Time:22.947532892227173 , Training Accuracy= 0.457\n",
      "Validation Accuracy: 0.4448\n",
      "Epoch 7, Time:24.492541790008545 , Training Accuracy= 0.463\n",
      "Validation Accuracy: 0.4492\n",
      "Epoch 8, Time:22.596689224243164 , Training Accuracy= 0.476\n",
      "Validation Accuracy: 0.4516\n",
      "Epoch 9, Time:24.00751304626465 , Training Accuracy= 0.480\n",
      "Validation Accuracy: 0.4602\n",
      "Epoch 10, Time:22.603589057922363 , Training Accuracy= 0.487\n",
      "Validation Accuracy: 0.4728\n",
      "Epoch 11, Time:21.3372585773468 , Training Accuracy= 0.497\n",
      "Validation Accuracy: 0.4752\n",
      "Epoch 12, Time:18.378896474838257 , Training Accuracy= 0.498\n",
      "Validation Accuracy: 0.4732\n",
      "Epoch 13, Time:18.928412914276123 , Training Accuracy= 0.505\n",
      "Validation Accuracy: 0.4728\n",
      "Epoch 14, Time:19.55018973350525 , Training Accuracy= 0.512\n",
      "Validation Accuracy: 0.486\n",
      "Training finished!\n",
      "Testing Accuracy: 0.4867\n"
     ]
    }
   ],
   "source": [
    "#learning rate=.0001\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps):\n",
    "        #fetch batch\n",
    "        \n",
    "        acc=[]\n",
    "        st=time.time()\n",
    "        for j in range(1,6):\n",
    "            for (a,b) in load_cifar_template1.load_preprocessed_training_batch(j,1000):\n",
    "                batch_x, batch_y = a, b\n",
    "                #run optimization\n",
    "                sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "                \n",
    "                acc.append(sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y}))\n",
    "        mid=time.time()\n",
    "        print(\"Epoch \"+str(i)+\", Time:{} \".format(mid-st)+\", Training Accuracy= {:.3f}\".format(np.average(acc)))\n",
    "\n",
    "                    \n",
    "        batch_a,batch_b=load_cifar_template1.load_preprocessed_validation_batch()\n",
    "        val=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "        print(\"Validation Accuracy:\",val)\n",
    "    print(\"Training finished!\")\n",
    "    batch_a,batch_b=load_cifar_template1.load_preprocessed_test_batch()\n",
    "    test_acc=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "    print(\"Testing Accuracy:\",test_acc)\n",
    "#file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Time:19.955665826797485 , Training Accuracy= 0.246\n",
      "Validation Accuracy: 0.3036\n",
      "Epoch 1, Time:18.952347993850708 , Training Accuracy= 0.344\n",
      "Validation Accuracy: 0.376\n",
      "Epoch 2, Time:18.977282524108887 , Training Accuracy= 0.385\n",
      "Validation Accuracy: 0.3874\n",
      "Epoch 3, Time:19.66244888305664 , Training Accuracy= 0.409\n",
      "Validation Accuracy: 0.397\n",
      "Epoch 4, Time:18.834661722183228 , Training Accuracy= 0.432\n",
      "Validation Accuracy: 0.4166\n",
      "Epoch 5, Time:18.888516426086426 , Training Accuracy= 0.445\n",
      "Validation Accuracy: 0.4366\n",
      "Epoch 6, Time:19.36025834083557 , Training Accuracy= 0.458\n",
      "Validation Accuracy: 0.4432\n",
      "Epoch 7, Time:19.090977668762207 , Training Accuracy= 0.469\n",
      "Validation Accuracy: 0.4532\n",
      "Epoch 8, Time:19.296428442001343 , Training Accuracy= 0.482\n",
      "Validation Accuracy: 0.4564\n",
      "Epoch 9, Time:19.26949977874756 , Training Accuracy= 0.489\n",
      "Validation Accuracy: 0.475\n",
      "Training finished!\n",
      "Testing Accuracy: 0.4782\n"
     ]
    }
   ],
   "source": [
    "#learning rate=.001\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps):\n",
    "        #fetch batch\n",
    "        \n",
    "        acc=[]\n",
    "        st=time.time()\n",
    "        for j in range(1,6):\n",
    "            for (a,b) in load_cifar_template1.load_preprocessed_training_batch(j,1000):\n",
    "                batch_x, batch_y = a, b\n",
    "                #run optimization\n",
    "                sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "                \n",
    "                acc.append(sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y}))\n",
    "        mid=time.time()\n",
    "        print(\"Epoch \"+str(i)+\", Time:{} \".format(mid-st)+\", Training Accuracy= {:.3f}\".format(np.average(acc)))\n",
    "\n",
    "                    \n",
    "        batch_a,batch_b=load_cifar_template1.load_preprocessed_validation_batch()\n",
    "        val=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "        print(\"Validation Accuracy:\",val)\n",
    "    print(\"Training finished!\")\n",
    "    batch_a,batch_b=load_cifar_template1.load_preprocessed_test_batch()\n",
    "    test_acc=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "    print(\"Testing Accuracy:\",test_acc)\n",
    "#file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Time:19.21863293647766 , Training Accuracy= 0.294\n",
      "Validation Accuracy: 0.3296\n",
      "Epoch 1, Time:21.773850440979004 , Training Accuracy= 0.368\n",
      "Validation Accuracy: 0.379\n",
      "Epoch 2, Time:19.709324598312378 , Training Accuracy= 0.396\n",
      "Validation Accuracy: 0.393\n",
      "Epoch 3, Time:19.40014958381653 , Training Accuracy= 0.417\n",
      "Validation Accuracy: 0.4122\n",
      "Epoch 4, Time:21.576334953308105 , Training Accuracy= 0.433\n",
      "Validation Accuracy: 0.4194\n",
      "Epoch 5, Time:19.98758101463318 , Training Accuracy= 0.444\n",
      "Validation Accuracy: 0.4292\n",
      "Epoch 6, Time:19.296427965164185 , Training Accuracy= 0.453\n",
      "Validation Accuracy: 0.4272\n",
      "Epoch 7, Time:20.767496824264526 , Training Accuracy= 0.463\n",
      "Validation Accuracy: 0.4424\n",
      "Epoch 8, Time:19.67093515396118 , Training Accuracy= 0.470\n",
      "Validation Accuracy: 0.449\n",
      "Epoch 9, Time:19.26251983642578 , Training Accuracy= 0.479\n",
      "Validation Accuracy: 0.4538\n",
      "Training finished!\n",
      "Testing Accuracy: 0.4666\n"
     ]
    }
   ],
   "source": [
    "#learning rate=.0001\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps):\n",
    "        #fetch batch\n",
    "        \n",
    "        acc=[]\n",
    "        st=time.time()\n",
    "        for j in range(1,6):\n",
    "            for (a,b) in load_cifar_template1.load_preprocessed_training_batch(j,1000):\n",
    "                batch_x, batch_y = a, b\n",
    "                #run optimization\n",
    "                sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "                \n",
    "                acc.append(sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y}))\n",
    "        mid=time.time()\n",
    "        print(\"Epoch \"+str(i)+\", Time:{} \".format(mid-st)+\", Training Accuracy= {:.3f}\".format(np.average(acc)))\n",
    "\n",
    "                    \n",
    "        batch_a,batch_b=load_cifar_template1.load_preprocessed_validation_batch()\n",
    "        val=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "        print(\"Validation Accuracy:\",val)\n",
    "    print(\"Training finished!\")\n",
    "    batch_a,batch_b=load_cifar_template1.load_preprocessed_test_batch()\n",
    "    test_acc=sess.run(accuracy, feed_dict={X:batch_a, Y:batch_b})\n",
    "    print(\"Testing Accuracy:\",test_acc)\n",
    "#file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried with different learning rates, but interestingly it didn't seem to matter if I had a learning rate of .01-.0001. All of these produced a testing accuracy of around 50% at around 10 epochs. I did one test where I did 15 epochs since my computer couldn't seem to handle running more than that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
